{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Stochastic Optimization\n",
    "\n",
    "## 1.2 Simulated Annealing\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" align=\"left\" src=\"https://i.creativecommons.org/l/by-sa/4.0/80x15.png\" /></a>&nbsp;| Dennis G. Wilson | <a href=\"https://supaerodatascience.github.io/stochastic/\">https://supaerodatascience.github.io/stochastic/</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"560\"\n",
       "            height=\"315\"\n",
       "            src=\"https://youtube.com/embed/skQRLfU3plM?start=530\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x75585c196f60>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"https://youtube.com/embed/skQRLfU3plM?start=530\", 560, 315)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Simulated annealing is a stochastic search algorithm which improves on the idea of random optimization by basing the search not only on the best found state, but also on random states. To determine which states to accept, it uses a term called *temperature*. The algorithm is inspired by the process of metal annealing, where a metal must cool in a slow process to reach a desired hardened configuration of minimal energy.\n",
    "\n",
    "<img src=\"imgs/Simulated_Annealing.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Because simulated annealing is based on the metal cooling metaphor, the literature surrounding it often refers to fitness values in the search space as energies, where the objective is to minimize the energy (cool the metal) slowly. Arriving at a local minimum of energy by cooling too rapidly creates non-optimal atomic configurations of the metal, as is seen in real metals.\n",
    "\n",
    "<img src=\"imgs/simulated_annealing.png\">\n",
    "Delahaye, Daniel, Supatcha Chaimatanan, and Marcel Mongeau. \"Simulated annealing: From basics to applications.\" Handbook of Metaheuristics. Springer, Cham, 2019. 1-35."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simulated Annealing\n",
    "\n",
    "Let $f: \\mathbb{R}^n → \\mathbb{R}$ be the fitness or cost function which must be minimized. Let $x ∈ \\mathbb{R}^n$ designate a position or candidate solution in the search-space.\n",
    "\n",
    "    Initialize x randomly in ℝ\n",
    "    xbest = x\n",
    "    for k in {0, kmax}\n",
    "        x' = nearby(x)\n",
    "        if f(x′) < f(x)\n",
    "            x = x'\n",
    "        else\n",
    "            x = x' with probability P(f(x'), f(x), T)\n",
    "        if f(x) < f(xbest)\n",
    "            xbest = x\n",
    "    return xbest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "`nearby(x)` is a function which finds a point near X. This is a flexible definition, and we can continue to use the definition of $x' = x + N(0,1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The acceptance probability that $x = x'$ if $f(x') > f(x)$ is the difference between simulated annealing and random optimization seen in the last notebook. This probability allows the search to move away from local optima, accepting worse solutions in order to explore more of the search space. This probability depends on 3 terms: $f(x'), f(x),$ and $T$, the temperature. A common probability is:\n",
    "\n",
    "$e^\\frac{-(f(x')-f(x))}{T}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The temperature $T$ is the factor which determines the rate of exploration of the search space as opposed to exploitation of a specific optima. Often, the schedule used is to start with $T=1$ and to decrease at each time step to $T=\\frac{(k_{max}-k)}{k_{max}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's see some acceptance probabilities for different values of $f(x')$ and $T$ when $f(x)=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fx = np.arange(1.0, 2.0, 0.1)\n",
    "T = np.arange(1.0, 0.0, -0.1)\n",
    "X, Y = np.meshgrid(fx, T)\n",
    "proba = lambda fx, T :np.exp(-(fx - 1) / T)\n",
    "Z = proba(X, Y)\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "cs = plt.contourf(X, Y, Z)\n",
    "fig.colorbar(cs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As we can see, for high temperature values (ie the beginning of the search), there is a high probability to accept solutions which are worse than our current best. However, as the search continues and the temperature decreases, the chance of accepting higher values decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For a summary, here is the version of simulated annealing we can use for continuous optimization. Note that the choice of neighbor function, acceptance probability function, and temperature schedule are all parameters in simulated annealing and we could choose other functions suited to specific problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Continuous Optimization Simulated Annealing\n",
    "\n",
    "Let $f: \\mathbb{R}^n → \\mathbb{R}$ be the fitness or cost function which must be minimized. Let $x ∈ \\mathbb{R}^n$ designate a position or candidate solution in the search-space.\n",
    "\n",
    "    Initialize x randomly in ℝ\n",
    "    xbest = x\n",
    "    for k in {0, kmax}\n",
    "        x' = x + N(0, 1)\n",
    "        T = (kmax - k) / kmax\n",
    "        if (f(x′) < f(x)) or (exp(-(f(x')-f(x))/T) > rand())\n",
    "            x = x'\n",
    "            if f(x) < f(xbest)\n",
    "                xbest = x\n",
    "    return xbest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3>Exercise 3</h3>\n",
    "Implement simulated annealing and compare it to random search. Does the acceptance probability help? Try tracking when it is used to see if more transitions are accepted early in the search. Compare random search and simulated annealing on the Himmelblau function. Are the conclusions different?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# %load solutions/3_sa.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h3>Discussion</h3>\n",
    "At the beginning of class, we discussed the travelling salesman problem. This is a discrete optimization problem where a position in the search space represents the list of cities in the order that they will be visited. What would be a good `neighbor` function for this problem?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
